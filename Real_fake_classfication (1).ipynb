{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136120b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1558f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 11067: expected 4 fields, saw 8\\n'\n"
     ]
    }
   ],
   "source": [
    "df_fake= pd.read_csv('Fake.csv',  error_bad_lines=False, encoding= \"latin-1\")\n",
    "df_true= pd.read_csv('True.csv', error_bad_lines=False, encoding= \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b6be529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['news_class'] = 1\n",
    "df_fake['news_class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "836da588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  news_class  \n",
       "0  December 31, 2017            1  \n",
       "1  December 29, 2017            1  \n",
       "2  December 31, 2017            1  \n",
       "3  December 30, 2017            1  \n",
       "4  December 29, 2017            1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10783c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year\u0019...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama\u0019s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year\u0019...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama\u0019s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  news_class  \n",
       "0  December 31, 2017           0  \n",
       "1  December 31, 2017           0  \n",
       "2  December 30, 2017           0  \n",
       "3  December 29, 2017           0  \n",
       "4  December 25, 2017           0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae4eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanResume(resumeText):#resumText perform several operations to clean and preprocess the text of resume.\n",
    "    \n",
    "    resumeText = re.sub(r'[\\x1d\\x1c\\x1b]', '', resumeText)#remove special character\n",
    "    resumeText = re.sub(r'\\x19', ' ', resumeText) #to replace character \\x19 with space ' '.\n",
    "    resumeText = re.sub(r'\\s+', ' ', resumeText).strip()#remove whitespace\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    #resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    #resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'\\d+', '', resumeText)#remove number \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    return resumeText.lower()#returns clean \"resumeText\" and convert all text into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faeecc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true[\"text\"]=df_true.text.apply(cleanResume)\n",
    "df_fake[\"text\"]=df_fake.text.apply(cleanResume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3cc7b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>washington reuters the head of a conservative ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>washington reuters transgender people will be ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>washington reuters the special counsel investi...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>washington reuters trump campaign adviser geor...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>seattle washington reuters president donald tr...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  washington reuters the head of a conservative ...  politicsNews   \n",
       "1  washington reuters transgender people will be ...  politicsNews   \n",
       "2  washington reuters the special counsel investi...  politicsNews   \n",
       "3  washington reuters trump campaign adviser geor...  politicsNews   \n",
       "4  seattle washington reuters president donald tr...  politicsNews   \n",
       "\n",
       "                 date  news_class  \n",
       "0  December 31, 2017            1  \n",
       "1  December 29, 2017            1  \n",
       "2  December 31, 2017            1  \n",
       "3  December 30, 2017            1  \n",
       "4  December 29, 2017            1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a56a363f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year\u0019...</td>\n",
       "      <td>donald trump just couldn t wish all americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>house intelligence committee chairman devin nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>on friday it was revealed that former milwauke...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama\u0019s Name...</td>\n",
       "      <td>on christmas day donald trump announced that h...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>pope francis used his annual christmas day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year\u0019...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama\u0019s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  donald trump just couldn t wish all americans ...    News   \n",
       "1  house intelligence committee chairman devin nu...    News   \n",
       "2  on friday it was revealed that former milwauke...    News   \n",
       "3  on christmas day donald trump announced that h...    News   \n",
       "4  pope francis used his annual christmas day mes...    News   \n",
       "\n",
       "                date  news_class  \n",
       "0  December 31, 2017           0  \n",
       "1  December 31, 2017           0  \n",
       "2  December 30, 2017           0  \n",
       "3  December 29, 2017           0  \n",
       "4  December 25, 2017           0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53ec1da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df_true[\"text\"] = df_true.text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "203fb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake[\"text\"]= df_fake.text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed65ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>[washington, reuters, the, head, of, a, conser...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>[washington, reuters, transgender, people, wil...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>[washington, reuters, the, special, counsel, i...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>[washington, reuters, trump, campaign, adviser...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>[seattle, washington, reuters, president, dona...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  [washington, reuters, the, head, of, a, conser...  politicsNews   \n",
       "1  [washington, reuters, transgender, people, wil...  politicsNews   \n",
       "2  [washington, reuters, the, special, counsel, i...  politicsNews   \n",
       "3  [washington, reuters, trump, campaign, adviser...  politicsNews   \n",
       "4  [seattle, washington, reuters, president, dona...  politicsNews   \n",
       "\n",
       "                 date  news_class  \n",
       "0  December 31, 2017            1  \n",
       "1  December 29, 2017            1  \n",
       "2  December 31, 2017            1  \n",
       "3  December 30, 2017            1  \n",
       "4  December 29, 2017            1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0864815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing Stop words \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b9bc8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true[\"text\"] = df_true.text.apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ba79405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake[\"text\"] = df_fake.text.apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7cdb4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>[washington, reuters, head, conservative, repu...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>[washington, reuters, transgender, people, all...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>[washington, reuters, special, counsel, invest...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>[washington, reuters, trump, campaign, adviser...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>[seattle, washington, reuters, president, dona...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  [washington, reuters, head, conservative, repu...  politicsNews   \n",
       "1  [washington, reuters, transgender, people, all...  politicsNews   \n",
       "2  [washington, reuters, special, counsel, invest...  politicsNews   \n",
       "3  [washington, reuters, trump, campaign, adviser...  politicsNews   \n",
       "4  [seattle, washington, reuters, president, dona...  politicsNews   \n",
       "\n",
       "                 date  news_class  \n",
       "0  December 31, 2017            1  \n",
       "1  December 29, 2017            1  \n",
       "2  December 31, 2017            1  \n",
       "3  December 30, 2017            1  \n",
       "4  December 29, 2017            1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d999c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year\u0019...</td>\n",
       "      <td>[donald, trump, wish, americans, happy, new, y...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>[house, intelligence, committee, chairman, dev...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>[friday, revealed, former, milwaukee, sheriff,...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama\u0019s Name...</td>\n",
       "      <td>[christmas, day, donald, trump, announced, wou...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>[pope, francis, used, annual, christmas, day, ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year\u0019...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama\u0019s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  [donald, trump, wish, americans, happy, new, y...    News   \n",
       "1  [house, intelligence, committee, chairman, dev...    News   \n",
       "2  [friday, revealed, former, milwaukee, sheriff,...    News   \n",
       "3  [christmas, day, donald, trump, announced, wou...    News   \n",
       "4  [pope, francis, used, annual, christmas, day, ...    News   \n",
       "\n",
       "                date  news_class  \n",
       "0  December 31, 2017           0  \n",
       "1  December 31, 2017           0  \n",
       "2  December 30, 2017           0  \n",
       "3  December 29, 2017           0  \n",
       "4  December 25, 2017           0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "485eefbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53840935",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df_true[\"text\"] = df_true.text.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16096c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake[\"text\"] = df_fake.text.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1c229434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.to_csv(\"fake_lemma.csv\", index=False, header=True)\n",
    "df_true.to_csv(\"true_lemma.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63c8cf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>[washington, reuters, head, conservative, repu...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>[washington, reuters, transgender, people, all...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>[washington, reuters, special, counsel, invest...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>[washington, reuters, trump, campaign, adviser...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>[seattle, washington, reuters, president, dona...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  [washington, reuters, head, conservative, repu...  politicsNews   \n",
       "1  [washington, reuters, transgender, people, all...  politicsNews   \n",
       "2  [washington, reuters, special, counsel, invest...  politicsNews   \n",
       "3  [washington, reuters, trump, campaign, adviser...  politicsNews   \n",
       "4  [seattle, washington, reuters, president, dona...  politicsNews   \n",
       "\n",
       "                 date  news_class  \n",
       "0  December 31, 2017            1  \n",
       "1  December 29, 2017            1  \n",
       "2  December 31, 2017            1  \n",
       "3  December 30, 2017            1  \n",
       "4  December 29, 2017            1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f97695fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>news_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year\u0019...</td>\n",
       "      <td>[donald, trump, wish, american, happy, new, ye...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>[house, intelligence, committee, chairman, dev...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>[friday, revealed, former, milwaukee, sheriff,...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama\u0019s Name...</td>\n",
       "      <td>[christmas, day, donald, trump, announced, wou...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>[pope, francis, used, annual, christmas, day, ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year\u0019...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama\u0019s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  [donald, trump, wish, american, happy, new, ye...    News   \n",
       "1  [house, intelligence, committee, chairman, dev...    News   \n",
       "2  [friday, revealed, former, milwaukee, sheriff,...    News   \n",
       "3  [christmas, day, donald, trump, announced, wou...    News   \n",
       "4  [pope, francis, used, annual, christmas, day, ...    News   \n",
       "\n",
       "                date  news_class  \n",
       "0  December 31, 2017           0  \n",
       "1  December 31, 2017           0  \n",
       "2  December 30, 2017           0  \n",
       "3  December 29, 2017           0  \n",
       "4  December 25, 2017           0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "404425c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [donald, trump, wish, american, happy, new, ye...\n",
       "1        [house, intelligence, committee, chairman, dev...\n",
       "2        [friday, revealed, former, milwaukee, sheriff,...\n",
       "3        [christmas, day, donald, trump, announced, wou...\n",
       "4        [pope, francis, used, annual, christmas, day, ...\n",
       "                               ...                        \n",
       "23476    [st, century, wire, say, wire, reported, earli...\n",
       "23477    [st, century, wire, say, familiar, theme, when...\n",
       "23478    [patrick, henningsen, st, century, wireremembe...\n",
       "23479    [st, century, wire, say, al, jazeera, america,...\n",
       "23480    [st, century, wire, say, wire, predicted, new,...\n",
       "Name: text, Length: 23481, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c9da951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [washington, reuters, head, conservative, repu...\n",
       "1        [washington, reuters, transgender, people, all...\n",
       "2        [washington, reuters, special, counsel, invest...\n",
       "3        [washington, reuters, trump, campaign, adviser...\n",
       "4        [seattle, washington, reuters, president, dona...\n",
       "                               ...                        \n",
       "21411    [brussels, reuters, nato, ally, tuesday, welco...\n",
       "21412    [london, reuters, lexisnexis, provider, legal,...\n",
       "21413    [minsk, reuters, shadow, disused, soviet, era,...\n",
       "21414    [moscow, reuters, vatican, secretary, state, c...\n",
       "21415    [jakarta, reuters, indonesia, buy, sukhoi, fig...\n",
       "Name: text, Length: 21416, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6ca0e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true['corpus_t'] = df_true['text'].apply(lambda x: ' '.join(x))\n",
    "corpus_t = df_true['corpus_t'].tolist()  # Convert the corpus_t column to a list\n",
    "df_fake['corpus_f'] = df_fake['text'].apply(lambda x: ' '.join(x))\n",
    "corpus_f = df_fake['corpus_f'].tolist()  # Convert the corpus_f column to a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff056d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "\n",
    "def get_ngrams(corpus, n):\n",
    "    ngrams_list = []\n",
    "    for text in corpus:\n",
    "        tokens = word_tokenize(text)  # Tokenize the text into words\n",
    "        ngrams_list.extend(list(ngrams(tokens, n)))  # Generate n-grams\n",
    "    return ngrams_list\n",
    "\n",
    "def get_top_ngrams(corpus_t, corpus_f, n, top_k=100):\n",
    "    # Get n-grams for corpus_t\n",
    "    ngrams_t = Counter(get_ngrams(corpus_t, n))\n",
    "\n",
    "    # Get n-grams for corpus_f\n",
    "    ngrams_f = Counter(get_ngrams(corpus_f, n))\n",
    "\n",
    "    # Get top k frequent common n-grams\n",
    "    common_ngrams = set(ngrams_t.keys()) & set(ngrams_f.keys())\n",
    "    top_common_ngrams = sorted(common_ngrams, key=lambda x: ngrams_t[x] + ngrams_f[x], reverse=True)[:top_k]\n",
    "\n",
    "    # Get top k unique n-grams for corpus_t\n",
    "    unique_ngrams_t = set(ngrams_t.keys()) - set(ngrams_f.keys())\n",
    "    top_unique_ngrams_t = sorted(unique_ngrams_t, key=lambda x: ngrams_t[x], reverse=True)[:top_k]\n",
    "\n",
    "    # Get top k unique n-grams for corpus_f\n",
    "    unique_ngrams_f = set(ngrams_f.keys()) - set(ngrams_t.keys())\n",
    "    top_unique_ngrams_f = sorted(unique_ngrams_f, key=lambda x: ngrams_f[x], reverse=True)[:top_k]\n",
    "\n",
    "    return top_common_ngrams, top_unique_ngrams_t, top_unique_ngrams_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7d11af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigrams\n",
    "n =1 \n",
    "top_common_unigrams, top_unique_unigrams_t, top_unique_unigrams_f = get_top_ngrams(corpus_t, corpus_f, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3b134285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 frequent common unigrams:\n",
      "('trump',)\n",
      "('said',)\n",
      "('u',)\n",
      "('state',)\n",
      "('president',)\n",
      "('would',)\n",
      "('people',)\n",
      "('year',)\n",
      "('republican',)\n",
      "('one',)\n",
      "('reuters',)\n",
      "('new',)\n",
      "('also',)\n",
      "('government',)\n",
      "('house',)\n",
      "('donald',)\n",
      "('clinton',)\n",
      "('obama',)\n",
      "('time',)\n",
      "('country',)\n",
      "('say',)\n",
      "('american',)\n",
      "('election',)\n",
      "('party',)\n",
      "('right',)\n",
      "('united',)\n",
      "('could',)\n",
      "('told',)\n",
      "('white',)\n",
      "('campaign',)\n",
      "('like',)\n",
      "('two',)\n",
      "('last',)\n",
      "('official',)\n",
      "('first',)\n",
      "('group',)\n",
      "('law',)\n",
      "('news',)\n",
      "('washington',)\n",
      "('former',)\n",
      "('day',)\n",
      "('make',)\n",
      "('even',)\n",
      "('vote',)\n",
      "('week',)\n",
      "('get',)\n",
      "('court',)\n",
      "('hillary',)\n",
      "('security',)\n",
      "('want',)\n",
      "('many',)\n",
      "('national',)\n",
      "('democrat',)\n",
      "('woman',)\n",
      "('may',)\n",
      "('leader',)\n",
      "('made',)\n",
      "('image',)\n",
      "('percent',)\n",
      "('million',)\n",
      "('bill',)\n",
      "('police',)\n",
      "('know',)\n",
      "('since',)\n",
      "('month',)\n",
      "('administration',)\n",
      "('twitter',)\n",
      "('way',)\n",
      "('going',)\n",
      "('think',)\n",
      "('tax',)\n",
      "('support',)\n",
      "('back',)\n",
      "('take',)\n",
      "('political',)\n",
      "('presidential',)\n",
      "('statement',)\n",
      "('according',)\n",
      "('via',)\n",
      "('senate',)\n",
      "('office',)\n",
      "('democratic',)\n",
      "('america',)\n",
      "('called',)\n",
      "('medium',)\n",
      "('russia',)\n",
      "('member',)\n",
      "('north',)\n",
      "('policy',)\n",
      "('including',)\n",
      "('need',)\n",
      "('well',)\n",
      "('attack',)\n",
      "('department',)\n",
      "('go',)\n",
      "('candidate',)\n",
      "('city',)\n",
      "('federal',)\n",
      "('report',)\n",
      "('come',)\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 100 frequent common unigrams:\")\n",
    "for ngram in top_common_unigrams:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e79e21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 unique unigrams for corpus_t:\n",
      "('pas',)\n",
      "('catalan',)\n",
      "('rakhine',)\n",
      "('\\x13',)\n",
      "('zuma',)\n",
      "('puigdemont',)\n",
      "('fdp',)\n",
      "('kirkuk',)\n",
      "('suu',)\n",
      "('kyi',)\n",
      "('sdf',)\n",
      "('\\x14',)\n",
      "('mnangagwa',)\n",
      "('anc',)\n",
      "('rajoy',)\n",
      "('odinga',)\n",
      "('kuczynski',)\n",
      "('tmsnrt',)\n",
      "('krg',)\n",
      "('kurz',)\n",
      "('aung',)\n",
      "('ramaphosa',)\n",
      "('barzani',)\n",
      "('barnier',)\n",
      "('fpo',)\n",
      "('harare',)\n",
      "('babis',)\n",
      "('marawi',)\n",
      "('us',)\n",
      "('nairobi',)\n",
      "('kem',)\n",
      "('sokha',)\n",
      "('euphrates',)\n",
      "('zarrab',)\n",
      "('ass',)\n",
      "('yangon',)\n",
      "('pkk',)\n",
      "('carles',)\n",
      "('koike',)\n",
      "('farc',)\n",
      "('ldp',)\n",
      "('schaeuble',)\n",
      "('asean',)\n",
      "('lighthizer',)\n",
      "('odebrecht',)\n",
      "('nasralla',)\n",
      "('cnrp',)\n",
      "('pinera',)\n",
      "('cameroon',)\n",
      "('dlamini',)\n",
      "('najib',)\n",
      "('bazar',)\n",
      "('unionist',)\n",
      "('pass',)\n",
      "('ano',)\n",
      "('johannesburg',)\n",
      "('kiir',)\n",
      "('berlusconi',)\n",
      "('pdvsa',)\n",
      "('museveni',)\n",
      "('navalny',)\n",
      "('obrador',)\n",
      "('dup',)\n",
      "('kabila',)\n",
      "('fujimori',)\n",
      "('zaghari',)\n",
      "('refiner',)\n",
      "('mladic',)\n",
      "('mistura',)\n",
      "('caruana',)\n",
      "('haftar',)\n",
      "('galizia',)\n",
      "('fethullah',)\n",
      "('penh',)\n",
      "('phnom',)\n",
      "('drian',)\n",
      "('saakashvili',)\n",
      "('politburo',)\n",
      "('coveney',)\n",
      "('yingluck',)\n",
      "('accession',)\n",
      "('mogherini',)\n",
      "('taipei',)\n",
      "('soe',)\n",
      "('arsa',)\n",
      "('strache',)\n",
      "('sahel',)\n",
      "('exploratory',)\n",
      "('reimpose',)\n",
      "('raila',)\n",
      "('kyaw',)\n",
      "('emmerson',)\n",
      "('jpexyr',)\n",
      "('jbhlu',)\n",
      "('madigan',)\n",
      "('congolese',)\n",
      "('buhari',)\n",
      "('eln',)\n",
      "('brasilia',)\n",
      "('guillier',)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 unique unigrams for corpus_t:\")\n",
    "for ngram in top_unique_unigrams_t:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4552fbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 unique unigrams for corpus_f:\n",
      "('quot',)\n",
      "('a',)\n",
      "('flickr',)\n",
      "('fjs',)\n",
      "('somodevilla',)\n",
      "('var',)\n",
      "('cdata',)\n",
      "('angerer',)\n",
      "('mcnamee',)\n",
      "('wfb',)\n",
      "('wikimedia',)\n",
      "('nyp',)\n",
      "('cking',)\n",
      "('raedle',)\n",
      "('getelementbyid',)\n",
      "('src',)\n",
      "('whined',)\n",
      "('gitmo',)\n",
      "('createelement',)\n",
      "('behar',)\n",
      "('getelementsbytagname',)\n",
      "('parentnode',)\n",
      "('insertbefore',)\n",
      "('jssdk',)\n",
      "('wnd',)\n",
      "('cher',)\n",
      "('beyonc',)\n",
      "('finicum',)\n",
      "('xfbml',)\n",
      "('camerota',)\n",
      "('sdk',)\n",
      "('gage',)\n",
      "('affleck',)\n",
      "('weasel',)\n",
      "('hilariously',)\n",
      "('blacklivesmatter',)\n",
      "('dobbs',)\n",
      "('couric',)\n",
      "('sarahpalinusa',)\n",
      "('watters',)\n",
      "('grifter',)\n",
      "('rino',)\n",
      "('hissy',)\n",
      "('pee',)\n",
      "('olbermann',)\n",
      "('pirro',)\n",
      "('whoopi',)\n",
      "('tripp',)\n",
      "('sabo',)\n",
      "('elizabethforma',)\n",
      "('anncoulter',)\n",
      "('stelter',)\n",
      "('politifact',)\n",
      "('lefty',)\n",
      "('jordanuhl',)\n",
      "('gt',)\n",
      "('eichenwald',)\n",
      "('bessbell',)\n",
      "('tonyposnanski',)\n",
      "('schlussel',)\n",
      "('prisonplanet',)\n",
      "('snopes',)\n",
      "('yashar',)\n",
      "('zipper',)\n",
      "('addicting',)\n",
      "('keurig',)\n",
      "('piss',)\n",
      "('ayyadurai',)\n",
      "('posnanski',)\n",
      "('presssec',)\n",
      "('hmmm',)\n",
      "('bullsh',)\n",
      "('hammonds',)\n",
      "('loomer',)\n",
      "('buffoon',)\n",
      "('caplan',)\n",
      "('uhl',)\n",
      "('atty',)\n",
      "('mediaite',)\n",
      "('matthewdicks',)\n",
      "('crowder',)\n",
      "('tantaros',)\n",
      "('zeifman',)\n",
      "('mn',)\n",
      "('lavoy',)\n",
      "('bonifield',)\n",
      "('tawhidi',)\n",
      "('whiteness',)\n",
      "('letterman',)\n",
      "('jackposobiec',)\n",
      "('stachowiak',)\n",
      "('irving',)\n",
      "('commie',)\n",
      "('reiner',)\n",
      "('douliery',)\n",
      "('abcpolitics',)\n",
      "('bila',)\n",
      "('delusion',)\n",
      "('vitale',)\n",
      "('joshdcaplan',)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 unique unigrams for corpus_f:\")\n",
    "for ngram in top_unique_unigrams_f:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5d45cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams\n",
    "n = 2\n",
    "top_common_bigrams, top_unique_bigrams_t, top_unique_bigrams_f = get_top_ngrams(corpus_t, corpus_f, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "76366a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 frequent common bigrams:\n",
      "('donald', 'trump')\n",
      "('united', 'state')\n",
      "('white', 'house')\n",
      "('hillary', 'clinton')\n",
      "('new', 'york')\n",
      "('featured', 'image')\n",
      "('president', 'donald')\n",
      "('washington', 'reuters')\n",
      "('north', 'korea')\n",
      "('barack', 'obama')\n",
      "('year', 'old')\n",
      "('last', 'year')\n",
      "('trump', 'said')\n",
      "('prime', 'minister')\n",
      "('last', 'week')\n",
      "('said', 'statement')\n",
      "('president', 'trump')\n",
      "('supreme', 'court')\n",
      "('u', 'president')\n",
      "('official', 'said')\n",
      "('president', 'obama')\n",
      "('fox', 'news')\n",
      "('islamic', 'state')\n",
      "('president', 'barack')\n",
      "('u', 'n')\n",
      "('reuters', 'u')\n",
      "('secretary', 'state')\n",
      "('said', 'would')\n",
      "('trump', 'administration')\n",
      "('national', 'security')\n",
      "('told', 'reuters')\n",
      "('told', 'reporter')\n",
      "('trump', 'campaign')\n",
      "('state', 'department')\n",
      "('attorney', 'general')\n",
      "('last', 'month')\n",
      "('obama', 'administration')\n",
      "('united', 'nation')\n",
      "('presidential', 'election')\n",
      "('human', 'right')\n",
      "('said', 'trump')\n",
      "('presidential', 'candidate')\n",
      "('house', 'representative')\n",
      "('social', 'medium')\n",
      "('trump', 'supporter')\n",
      "('president', 'elect')\n",
      "('saudi', 'arabia')\n",
      "('republican', 'party')\n",
      "('vice', 'president')\n",
      "('republican', 'presidential')\n",
      "('donald', 'j')\n",
      "('j', 'trump')\n",
      "('european', 'union')\n",
      "('climate', 'change')\n",
      "('law', 'enforcement')\n",
      "('former', 'president')\n",
      "('said', 'wednesday')\n",
      "('ted', 'cruz')\n",
      "('police', 'officer')\n",
      "('year', 'ago')\n",
      "('justice', 'department')\n",
      "('foreign', 'minister')\n",
      "('bernie', 'sander')\n",
      "('american', 'people')\n",
      "('said', 'thursday')\n",
      "('trump', 'realdonaldtrump')\n",
      "('first', 'time')\n",
      "('york', 'time')\n",
      "('said', 'tuesday')\n",
      "('also', 'said')\n",
      "('executive', 'order')\n",
      "('bill', 'clinton')\n",
      "('u', 'senator')\n",
      "('two', 'year')\n",
      "('source', 'said')\n",
      "('middle', 'east')\n",
      "('said', 'friday')\n",
      "('presidential', 'campaign')\n",
      "('washington', 'post')\n",
      "('north', 'korean')\n",
      "('even', 'though')\n",
      "('u', 'official')\n",
      "('news', 'conference')\n",
      "('next', 'year')\n",
      "('wall', 'street')\n",
      "('south', 'korea')\n",
      "('foreign', 'policy')\n",
      "('said', 'monday')\n",
      "('right', 'wing')\n",
      "('vladimir', 'putin')\n",
      "('puerto', 'rico')\n",
      "('paul', 'ryan')\n",
      "('african', 'american')\n",
      "('democratic', 'party')\n",
      "('look', 'like')\n",
      "('u', 'senate')\n",
      "('security', 'council')\n",
      "('life', 'matter')\n",
      "('w', 'bush')\n",
      "('republican', 'senator')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 frequent common bigrams:\")\n",
    "for ngram in top_common_bigrams:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d8d7d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 unique bigrams for corpus_t:\n",
      "('york', 'reuters')\n",
      "('london', 'reuters')\n",
      "('shi', 'ite')\n",
      "('reuters', 'republican')\n",
      "('moscow', 'reuters')\n",
      "('berlin', 'reuters')\n",
      "('suu', 'kyi')\n",
      "('beijing', 'reuters')\n",
      "('euro', 'zone')\n",
      "('rakhine', 'state')\n",
      "('reuters', 'united')\n",
      "('beirut', 'reuters')\n",
      "('brussels', 'reuters')\n",
      "('president', 'tayyip')\n",
      "('hun', 'sen')\n",
      "('tmsnrt', 'r')\n",
      "('bit', 'ly')\n",
      "('regional', 'government')\n",
      "('paris', 'reuters')\n",
      "('reuters', 'former')\n",
      "('reuters', 'white')\n",
      "('reuters', 'china')\n",
      "('reuters', 'british')\n",
      "('ankara', 'reuters')\n",
      "('created', 'reuters')\n",
      "('reuters', 'editorial')\n",
      "('independently', 'created')\n",
      "('part', 'sap')\n",
      "('erdogan', 'said')\n",
      "('reuters', 'democratic')\n",
      "('main', 'opposition')\n",
      "('seoul', 'reuters')\n",
      "('tokyo', 'reuters')\n",
      "('reuters', 'new')\n",
      "('kem', 'sokha')\n",
      "('pro', 'independence')\n",
      "('reuters', 'russia')\n",
      "('aung', 'san')\n",
      "('reuters', 'britain')\n",
      "('san', 'suu')\n",
      "('reuters', 'european')\n",
      "('story', 'corrects')\n",
      "('geneva', 'reuters')\n",
      "('myanmar', 'military')\n",
      "('reuters', 'two')\n",
      "('reuters', 'german')\n",
      "('reuters', 'south')\n",
      "('madrid', 'reuters')\n",
      "('nation', 'reuters')\n",
      "('self', 'driving')\n",
      "('free', 'democrat')\n",
      "('dubai', 'reuters')\n",
      "('carles', 'puigdemont')\n",
      "('staff', 'sap')\n",
      "('creation', 'production')\n",
      "('sap', 'independently')\n",
      "('sap', 'editorial')\n",
      "('editorial', 'involvement')\n",
      "('article', 'funded')\n",
      "('story', 'refiled')\n",
      "('coalition', 'talk')\n",
      "('cairo', 'reuters')\n",
      "('single', 'market')\n",
      "('reuters', 'turkey')\n",
      "('brexit', 'talk')\n",
      "('mariano', 'rajoy')\n",
      "('manila', 'reuters')\n",
      "('dlamini', 'zuma')\n",
      "('representative', 'intelligence')\n",
      "('reuters', 'saudi')\n",
      "('ria', 'news')\n",
      "('reuters', 'turkish')\n",
      "('minister', 'mariano')\n",
      "('southeast', 'asia')\n",
      "('spanish', 'government')\n",
      "('cox', 'bazar')\n",
      "('sap', 'sponsor')\n",
      "('chicago', 'reuters')\n",
      "('kurdish', 'region')\n",
      "('baghdad', 'reuters')\n",
      "('istanbul', 'reuters')\n",
      "('reuters', 'north')\n",
      "('direct', 'rule')\n",
      "('click', 'tmsnrt')\n",
      "('harare', 'reuters')\n",
      "('democrat', 'fdp')\n",
      "('n', 'backed')\n",
      "('rohingya', 'militant')\n",
      "('snap', 'election')\n",
      "('kurdistan', 'regional')\n",
      "('rohingya', 'refugee')\n",
      "('eu', 'citizen')\n",
      "('zealand', 'first')\n",
      "('catalan', 'government')\n",
      "('democratic', 'force')\n",
      "('nairobi', 'reuters')\n",
      "('lopez', 'obrador')\n",
      "('leader', 'aung')\n",
      "('pas', 'legislation')\n",
      "('custom', 'union')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 unique bigrams for corpus_t:\")\n",
    "for ngram in top_unique_bigrams_t:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2cf4417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 unique bigrams for corpus_f:\n",
      "('image', 'via')\n",
      "('twitter', 'com')\n",
      "('pic', 'twitter')\n",
      "('getty', 'image')\n",
      "('screen', 'capture')\n",
      "('via', 'youtube')\n",
      "('via', 'getty')\n",
      "('january', 'realdonaldtrump')\n",
      "('via', 'screen')\n",
      "('via', 'breitbart')\n",
      "('entire', 'story')\n",
      "('chip', 'somodevilla')\n",
      "('via', 'screengrab')\n",
      "('somodevilla', 'getty')\n",
      "('alex', 'wong')\n",
      "('via', 'flickr')\n",
      "('j', 'fjs')\n",
      "('image', 'screenshot')\n",
      "('gateway', 'pundit')\n",
      "('seth', 'rich')\n",
      "('february', 'realdonaldtrump')\n",
      "('wong', 'getty')\n",
      "('via', 'screenshot')\n",
      "('drew', 'angerer')\n",
      "('pool', 'getty')\n",
      "('win', 'mcnamee')\n",
      "('via', 'chip')\n",
      "('via', 'daily')\n",
      "('amp', 'amp')\n",
      "('december', 'realdonaldtrump')\n",
      "('read', 'daily')\n",
      "('video', 'screenshot')\n",
      "('angerer', 'getty')\n",
      "('mcnamee', 'getty')\n",
      "('via', 'alex')\n",
      "('mark', 'wilson')\n",
      "('tucker', 'carlson')\n",
      "('quot', 'quot')\n",
      "('realdonaldtrump', 'january')\n",
      "('f', 'cking')\n",
      "('image', 'credit')\n",
      "('joe', 'raedle')\n",
      "('cdata', 'cdata')\n",
      "('realdonaldtrump', 'july')\n",
      "('via', 'drew')\n",
      "('var', 'j')\n",
      "('j', 'src')\n",
      "('parentnode', 'insertbefore')\n",
      "('document', 'script')\n",
      "('insertbefore', 'j')\n",
      "('j', 'createelement')\n",
      "('j', 'id')\n",
      "('fjs', 'document')\n",
      "('id', 'id')\n",
      "('createelement', 'j')\n",
      "('wilson', 'getty')\n",
      "('id', 'return')\n",
      "('getelementbyid', 'id')\n",
      "('facebook', 'jssdk')\n",
      "('function', 'id')\n",
      "('id', 'j')\n",
      "('getelementsbytagname', 'getelementbyid')\n",
      "('id', 'var')\n",
      "('return', 'j')\n",
      "('via', 'win')\n",
      "('fjs', 'getelementsbytagname')\n",
      "('fjs', 'parentnode')\n",
      "('script', 'facebook')\n",
      "('raedle', 'getty')\n",
      "('spencer', 'platt')\n",
      "('via', 'mark')\n",
      "('white', 'student')\n",
      "('video', 'featured')\n",
      "('realdonaldtrump', 'june')\n",
      "('j', 'xfbml')\n",
      "('connect', 'facebook')\n",
      "('facebook', 'net')\n",
      "('src', 'connect')\n",
      "('via', 'gateway')\n",
      "('version', 'v')\n",
      "('sdk', 'j')\n",
      "('net', 'en')\n",
      "('justin', 'sullivan')\n",
      "('realdonaldtrump', 'september')\n",
      "('realdonaldtrump', 'december')\n",
      "('realdonaldtrump', 'october')\n",
      "('gage', 'skidmore')\n",
      "('xfbml', 'version')\n",
      "('v', 'fjs')\n",
      "('march', 'realdonaldtrump')\n",
      "('platt', 'getty')\n",
      "('trump', 'featured')\n",
      "('sullivan', 'getty')\n",
      "('cnn', 'host')\n",
      "('realdonaldtrump', 'february')\n",
      "('realdonaldtrump', 'august')\n",
      "('news', 'foxnews')\n",
      "('hannity', 'seanhannity')\n",
      "('via', 'washington')\n",
      "('project', 'veritas')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 unique bigrams for corpus_f:\")\n",
    "for ngram in top_unique_bigrams_f:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "603e86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigrams\n",
    "n = 3\n",
    "top_common_trigrams, top_unique_trigrams_t, top_unique_trigrams_f = get_top_ngrams(corpus_t, corpus_f, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b9ddf812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 frequent common trigrams:\n",
      "('president', 'donald', 'trump')\n",
      "('president', 'barack', 'obama')\n",
      "('u', 'president', 'donald')\n",
      "('washington', 'reuters', 'u')\n",
      "('donald', 'j', 'trump')\n",
      "('new', 'york', 'time')\n",
      "('black', 'life', 'matter')\n",
      "('reuters', 'u', 'president')\n",
      "('george', 'w', 'bush')\n",
      "('president', 'united', 'state')\n",
      "('elect', 'donald', 'trump')\n",
      "('white', 'house', 'said')\n",
      "('president', 'elect', 'donald')\n",
      "('new', 'york', 'city')\n",
      "('president', 'vladimir', 'putin')\n",
      "('affordable', 'care', 'act')\n",
      "('national', 'security', 'adviser')\n",
      "('speaker', 'paul', 'ryan')\n",
      "('respond', 'request', 'comment')\n",
      "('republican', 'presidential', 'candidate')\n",
      "('u', 'house', 'representative')\n",
      "('director', 'james', 'comey')\n",
      "('former', 'president', 'barack')\n",
      "('fbi', 'director', 'james')\n",
      "('secretary', 'state', 'rex')\n",
      "('state', 'rex', 'tillerson')\n",
      "('russian', 'president', 'vladimir')\n",
      "('donald', 'trump', 'said')\n",
      "('leader', 'mitch', 'mcconnell')\n",
      "('u', 'secretary', 'state')\n",
      "('former', 'secretary', 'state')\n",
      "('chancellor', 'angela', 'merkel')\n",
      "('white', 'house', 'official')\n",
      "('minister', 'theresa', 'may')\n",
      "('prime', 'minister', 'theresa')\n",
      "('candidate', 'donald', 'trump')\n",
      "('senate', 'majority', 'leader')\n",
      "('u', 'supreme', 'court')\n",
      "('republican', 'presidential', 'nominee')\n",
      "('u', 'presidential', 'election')\n",
      "('majority', 'leader', 'mitch')\n",
      "('president', 'george', 'w')\n",
      "('u', 'n', 'security')\n",
      "('n', 'security', 'council')\n",
      "('nominee', 'donald', 'trump')\n",
      "('department', 'homeland', 'security')\n",
      "('kim', 'jong', 'un')\n",
      "('wall', 'street', 'journal')\n",
      "('south', 'china', 'sea')\n",
      "('islamic', 'state', 'militant')\n",
      "('house', 'speaker', 'paul')\n",
      "('candidate', 'hillary', 'clinton')\n",
      "('said', 'united', 'state')\n",
      "('trump', 'white', 'house')\n",
      "('president', 'xi', 'jinping')\n",
      "('make', 'america', 'great')\n",
      "('white', 'house', 'spokesman')\n",
      "('donald', 'trump', 'jr')\n",
      "('told', 'news', 'conference')\n",
      "('u', 'official', 'said')\n",
      "('democrat', 'hillary', 'clinton')\n",
      "('president', 'bill', 'clinton')\n",
      "('president', 'mike', 'penny')\n",
      "('vice', 'president', 'mike')\n",
      "('democratic', 'national', 'committee')\n",
      "('u', 'state', 'department')\n",
      "('democratic', 'presidential', 'candidate')\n",
      "('u', 'intelligence', 'agency')\n",
      "('federal', 'bureau', 'investigation')\n",
      "('supreme', 'court', 'justice')\n",
      "('democratic', 'president', 'barack')\n",
      "('bashar', 'al', 'assad')\n",
      "('white', 'house', 'press')\n",
      "('entering', 'united', 'state')\n",
      "('presidential', 'candidate', 'donald')\n",
      "('immediately', 'respond', 'request')\n",
      "('senator', 'john', 'mccain')\n",
      "('trump', 'transition', 'team')\n",
      "('north', 'korea', 'nuclear')\n",
      "('united', 'state', 'would')\n",
      "('president', 'emmanuel', 'macron')\n",
      "('u', 'president', 'elect')\n",
      "('president', 'bashar', 'al')\n",
      "('private', 'email', 'server')\n",
      "('free', 'trade', 'agreement')\n",
      "('attorney', 'general', 'jeff')\n",
      "('u', 'president', 'barack')\n",
      "('general', 'jeff', 'session')\n",
      "('environmental', 'protection', 'agency')\n",
      "('special', 'counsel', 'robert')\n",
      "('said', 'last', 'week')\n",
      "('counsel', 'robert', 'mueller')\n",
      "('british', 'prime', 'minister')\n",
      "('deir', 'al', 'zor')\n",
      "('republican', 'donald', 'trump')\n",
      "('republican', 'national', 'committee')\n",
      "('senate', 'intelligence', 'committee')\n",
      "('senator', 'ted', 'cruz')\n",
      "('presidential', 'nominee', 'donald')\n",
      "('foreign', 'ministry', 'said')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 frequent common trigrams:\")\n",
    "for ngram in top_common_trigrams:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fb968999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 unique trigrams for corpus_t:\n",
      "('new', 'york', 'reuters')\n",
      "('washington', 'reuters', 'president')\n",
      "('reuters', 'president', 'donald')\n",
      "('washington', 'reuters', 'republican')\n",
      "('president', 'tayyip', 'erdogan')\n",
      "('reuters', 'u', 'senate')\n",
      "('reuters', 'united', 'state')\n",
      "('reuters', 'u', 'house')\n",
      "('reuters', 'white', 'house')\n",
      "('senate', 'democratic', 'leader')\n",
      "('reuters', 'editorial', 'staff')\n",
      "('created', 'reuters', 'editorial')\n",
      "('funded', 'part', 'sap')\n",
      "('independently', 'created', 'reuters')\n",
      "('representative', 'speaker', 'paul')\n",
      "('mexico', 'city', 'reuters')\n",
      "('reuters', 'president', 'barack')\n",
      "('washington', 'reuters', 'white')\n",
      "('source', 'told', 'reuters')\n",
      "('beijing', 'reuters', 'china')\n",
      "('san', 'suu', 'kyi')\n",
      "('aung', 'san', 'suu')\n",
      "('reuters', 'republican', 'presidential')\n",
      "('ministry', 'said', 'statement')\n",
      "('united', 'nation', 'reuters')\n",
      "('reuters', 'u', 'republican')\n",
      "('moscow', 'reuters', 'russian')\n",
      "('immediately', 'available', 'comment')\n",
      "('london', 'reuters', 'british')\n",
      "('sap', 'independently', 'created')\n",
      "('part', 'sap', 'independently')\n",
      "('article', 'funded', 'part')\n",
      "('editorial', 'involvement', 'creation')\n",
      "('staff', 'sap', 'editorial')\n",
      "('involvement', 'creation', 'production')\n",
      "('sap', 'editorial', 'involvement')\n",
      "('editorial', 'staff', 'sap')\n",
      "('democratic', 'leader', 'chuck')\n",
      "('turkish', 'president', 'tayyip')\n",
      "('spokeswoman', 'sarah', 'sander')\n",
      "('reuters', 'u', 'secretary')\n",
      "('house', 'representative', 'intelligence')\n",
      "('washington', 'reuters', 'united')\n",
      "('berlin', 'reuters', 'german')\n",
      "('ria', 'news', 'agency')\n",
      "('york', 'reuters', 'u')\n",
      "('republican', 'u', 'representative')\n",
      "('prime', 'minister', 'mariano')\n",
      "('representative', 'intelligence', 'committee')\n",
      "('minister', 'mariano', 'rajoy')\n",
      "('moscow', 'reuters', 'russia')\n",
      "('u', 'treasury', 'secretary')\n",
      "('click', 'tmsnrt', 'r')\n",
      "('u', 'n', 'backed')\n",
      "('kremlin', 'spokesman', 'dmitry')\n",
      "('free', 'democrat', 'fdp')\n",
      "('kurdistan', 'regional', 'government')\n",
      "('london', 'reuters', 'britain')\n",
      "('new', 'zealand', 'first')\n",
      "('reuters', 'trump', 'administration')\n",
      "('leader', 'aung', 'san')\n",
      "('u', 'senator', 'ted')\n",
      "('syrian', 'democratic', 'force')\n",
      "('reuters', 'european', 'union')\n",
      "('pro', 'business', 'free')\n",
      "('reuters', 'president', 'elect')\n",
      "('washington', 'reuters', 'democratic')\n",
      "('shi', 'ite', 'militia')\n",
      "('business', 'free', 'democrat')\n",
      "('san', 'francisco', 'reuters')\n",
      "('private', 'equity', 'firm')\n",
      "('brussels', 'reuters', 'european')\n",
      "('shi', 'ite', 'muslim')\n",
      "('reuters', 'british', 'prime')\n",
      "('republican', 'leader', 'mitch')\n",
      "('opinion', 'poll', 'show')\n",
      "('nuclear', 'tipped', 'missile')\n",
      "('reuters', 'united', 'nation')\n",
      "('angela', 'merkel', 'conservative')\n",
      "('washington', 'reuters', 'former')\n",
      "('self', 'driving', 'car')\n",
      "('reuters', 'republican', 'u')\n",
      "('washington', 'reuters', 'trump')\n",
      "('washington', 'reuters', 'top')\n",
      "('reuters', 'russian', 'president')\n",
      "('theresa', 'may', 'said')\n",
      "('secretary', 'boris', 'johnson')\n",
      "('reuters', 'democratic', 'presidential')\n",
      "('foreign', 'secretary', 'boris')\n",
      "('last', 'year', 'u')\n",
      "('link', 'bit', 'ly')\n",
      "('source', 'link', 'bit')\n",
      "('opposition', 'labour', 'party')\n",
      "('washington', 'reuters', 'donald')\n",
      "('billion', 'euro', 'billion')\n",
      "('bit', 'ly', 'jbhlu')\n",
      "('bit', 'ly', 'jpexyr')\n",
      "('donald', 'trump', 'realdonaldtrump')\n",
      "('told', 'news', 'briefing')\n",
      "('ly', 'jbhlu', 'bit')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 unique trigrams for corpus_t:\")\n",
    "for ngram in top_unique_trigrams_t:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "283e9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 unique trigrams for corpus_f:\n",
      "('president', 'donald', 'trump')\n",
      "('president', 'barack', 'obama')\n",
      "('u', 'president', 'donald')\n",
      "('washington', 'reuters', 'u')\n",
      "('donald', 'j', 'trump')\n",
      "('new', 'york', 'time')\n",
      "('black', 'life', 'matter')\n",
      "('reuters', 'u', 'president')\n",
      "('george', 'w', 'bush')\n",
      "('president', 'united', 'state')\n",
      "('elect', 'donald', 'trump')\n",
      "('white', 'house', 'said')\n",
      "('president', 'elect', 'donald')\n",
      "('new', 'york', 'city')\n",
      "('president', 'vladimir', 'putin')\n",
      "('affordable', 'care', 'act')\n",
      "('national', 'security', 'adviser')\n",
      "('speaker', 'paul', 'ryan')\n",
      "('respond', 'request', 'comment')\n",
      "('republican', 'presidential', 'candidate')\n",
      "('u', 'house', 'representative')\n",
      "('director', 'james', 'comey')\n",
      "('former', 'president', 'barack')\n",
      "('fbi', 'director', 'james')\n",
      "('secretary', 'state', 'rex')\n",
      "('state', 'rex', 'tillerson')\n",
      "('russian', 'president', 'vladimir')\n",
      "('donald', 'trump', 'said')\n",
      "('leader', 'mitch', 'mcconnell')\n",
      "('u', 'secretary', 'state')\n",
      "('former', 'secretary', 'state')\n",
      "('chancellor', 'angela', 'merkel')\n",
      "('white', 'house', 'official')\n",
      "('minister', 'theresa', 'may')\n",
      "('prime', 'minister', 'theresa')\n",
      "('candidate', 'donald', 'trump')\n",
      "('senate', 'majority', 'leader')\n",
      "('u', 'supreme', 'court')\n",
      "('republican', 'presidential', 'nominee')\n",
      "('u', 'presidential', 'election')\n",
      "('majority', 'leader', 'mitch')\n",
      "('president', 'george', 'w')\n",
      "('u', 'n', 'security')\n",
      "('n', 'security', 'council')\n",
      "('nominee', 'donald', 'trump')\n",
      "('department', 'homeland', 'security')\n",
      "('kim', 'jong', 'un')\n",
      "('wall', 'street', 'journal')\n",
      "('south', 'china', 'sea')\n",
      "('islamic', 'state', 'militant')\n",
      "('house', 'speaker', 'paul')\n",
      "('candidate', 'hillary', 'clinton')\n",
      "('said', 'united', 'state')\n",
      "('trump', 'white', 'house')\n",
      "('president', 'xi', 'jinping')\n",
      "('make', 'america', 'great')\n",
      "('white', 'house', 'spokesman')\n",
      "('donald', 'trump', 'jr')\n",
      "('told', 'news', 'conference')\n",
      "('u', 'official', 'said')\n",
      "('democrat', 'hillary', 'clinton')\n",
      "('president', 'bill', 'clinton')\n",
      "('president', 'mike', 'penny')\n",
      "('vice', 'president', 'mike')\n",
      "('democratic', 'national', 'committee')\n",
      "('u', 'state', 'department')\n",
      "('democratic', 'presidential', 'candidate')\n",
      "('u', 'intelligence', 'agency')\n",
      "('federal', 'bureau', 'investigation')\n",
      "('supreme', 'court', 'justice')\n",
      "('democratic', 'president', 'barack')\n",
      "('bashar', 'al', 'assad')\n",
      "('white', 'house', 'press')\n",
      "('entering', 'united', 'state')\n",
      "('presidential', 'candidate', 'donald')\n",
      "('immediately', 'respond', 'request')\n",
      "('senator', 'john', 'mccain')\n",
      "('trump', 'transition', 'team')\n",
      "('north', 'korea', 'nuclear')\n",
      "('united', 'state', 'would')\n",
      "('president', 'emmanuel', 'macron')\n",
      "('u', 'president', 'elect')\n",
      "('president', 'bashar', 'al')\n",
      "('private', 'email', 'server')\n",
      "('free', 'trade', 'agreement')\n",
      "('attorney', 'general', 'jeff')\n",
      "('u', 'president', 'barack')\n",
      "('general', 'jeff', 'session')\n",
      "('environmental', 'protection', 'agency')\n",
      "('special', 'counsel', 'robert')\n",
      "('said', 'last', 'week')\n",
      "('counsel', 'robert', 'mueller')\n",
      "('british', 'prime', 'minister')\n",
      "('deir', 'al', 'zor')\n",
      "('republican', 'donald', 'trump')\n",
      "('republican', 'national', 'committee')\n",
      "('senate', 'intelligence', 'committee')\n",
      "('senator', 'ted', 'cruz')\n",
      "('presidential', 'nominee', 'donald')\n",
      "('foreign', 'ministry', 'said')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 100 unique trigrams for corpus_f:\")\n",
    "for ngram in top_common_trigrams:\n",
    "    print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dc244779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\"Top 100 common unigrams\":top_common_unigrams, \n",
    "      \"100_unique_words_true\":top_unique_unigrams_t, \n",
    "      \"100_unique_words_fake\":top_unique_unigrams_f, \n",
    "      \"Top_100_common_bigrams\":top_common_bigrams,\n",
    "      \"100_unique_bigrams_true\":top_unique_bigrams_t,\n",
    "      \"100_unique_bigrams_fake\":top_unique_bigrams_f,\n",
    "      \"Top_100_common_trigrams\":top_common_trigrams,\n",
    "      \"100_unique_trigrams_true\":top_unique_trigrams_t,\n",
    "      \"100_unique_trigrams_fake\":top_unique_trigrams_f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "763b78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e8604812",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"True_fake_words2.csv\", index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "442b64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ngrams(corpus, ngrams_list):\n",
    "    for ngram in ngrams_list:\n",
    "        while ngram in corpus:\n",
    "            corpus.remove(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3b590bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ngrams(corpus_t, top_common_unigrams)\n",
    "remove_ngrams(corpus_f, top_common_unigrams)\n",
    "remove_ngrams(corpus_t, top_common_bigrams)\n",
    "remove_ngrams(corpus_f, top_common_bigrams)\n",
    "remove_ngrams(corpus_t, top_common_trigrams)\n",
    "remove_ngrams(corpus_f, top_common_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2b23f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus_t + corpus_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0bfa13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0] * len(corpus_f) + [1] * len(corpus_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "11b6aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b6525556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score,precision_score,confusion_matrix,recall_score,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "36ed8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91e5272",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15080\\3876018315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40beb61e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15080\\2346935414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of Model: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-------------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Classification report: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_rf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-------------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy =round(accuracy(y_test,y_pred),4)\n",
    "print(\"Accuracy of Model: \",accuracy_rf)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Classification report: \\n\",classification_report(y_test,y_pred_rf))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"confusion matrix: \\n\",confusion_matrix(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0f13a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "tfidf_array2 = tfidf_matrix.toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ababcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array2, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "21ceb47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884440294151978\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "38eb3450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970001167269756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 2), max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "tfidf_array3 = tfidf_matrix.toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array3, labels, test_size=0.2, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "accuracy_rf =round(accuracy_score(y_test,y_pred),4)\n",
    "print(\"Accuracy of Model: \",accuracy_rf)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Classification report: \\n\",classification_report(y_test,y_pred_rf))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"confusion matrix: \\n\",confusion_matrix(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "bfb489d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9383681568810552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3, 3), max_features=3000)\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "tfidf_array4 = tfidf_matrix.toarray()\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array4, labels, test_size=0.2, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4e7a0194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array, labels, test_size=0.2, random_state=42)\n",
    "rf.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9a679296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model:  0.9978\n",
      "-------------------------------------------\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4305\n",
      "           1       1.00      1.00      1.00      4262\n",
      "\n",
      "    accuracy                           1.00      8567\n",
      "   macro avg       1.00      1.00      1.00      8567\n",
      "weighted avg       1.00      1.00      1.00      8567\n",
      "\n",
      "-------------------------------------------\n",
      "confusion matrix: \n",
      " [[4295   10]\n",
      " [   9 4253]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(x_test)\n",
    "accuracy_rf =round(accuracy_score(y_test,y_pred_rf),4)\n",
    "print(\"Accuracy of Model: \",accuracy_rf)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Classification report: \\n\",classification_report(y_test,y_pred_rf))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"confusion matrix: \\n\",confusion_matrix(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7f63a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model:  0.975\n",
      "-------------------------------------------\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      4305\n",
      "           1       0.98      0.97      0.97      4262\n",
      "\n",
      "    accuracy                           0.98      8567\n",
      "   macro avg       0.98      0.97      0.98      8567\n",
      "weighted avg       0.98      0.98      0.98      8567\n",
      "\n",
      "-------------------------------------------\n",
      "confusion matrix: \n",
      " [[4229   76]\n",
      " [ 138 4124]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array2, labels, test_size=0.2, random_state=42)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "accuracy_rf =round(accuracy_score(y_test,y_pred_rf),4)\n",
    "print(\"Accuracy of Model: \",accuracy_rf)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Classification report: \\n\",classification_report(y_test,y_pred_rf))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"confusion matrix: \\n\",confusion_matrix(y_test,y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2d25ee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model:  0.9363\n",
      "-------------------------------------------\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      4305\n",
      "           1       0.94      0.93      0.94      4262\n",
      "\n",
      "    accuracy                           0.94      8567\n",
      "   macro avg       0.94      0.94      0.94      8567\n",
      "weighted avg       0.94      0.94      0.94      8567\n",
      "\n",
      "-------------------------------------------\n",
      "confusion matrix: \n",
      " [[4060  245]\n",
      " [ 301 3961]]\n"
     ]
    }
   ],
   "source": [
    "nb=MultinomialNB()\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array, labels, test_size=0.2, random_state=42)\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred_nb = nb.predict(x_test)\n",
    "accuracy_nb =round(accuracy_score(y_test,y_pred_nb),4)\n",
    "print(\"Accuracy of Model: \",accuracy_nb)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Classification report: \\n\",classification_report(y_test,y_pred_nb))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"confusion matrix: \\n\",confusion_matrix(y_test,y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656c7834",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15080\\1287131436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maccuracy_dt\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array, labels, test_size=0.2, random_state=42)\n",
    "dt.fit(x_train,y_train)\n",
    "y_pred_dt = dt.predict(x_test)\n",
    "accuracy_dt =round(accuracy_score(y_test,y_pred_dt),4)\n",
    "print(\"Accuracy of Model: \",accuracy_dt)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Classification report: \\n\",classification_report(y_test,y_pred_dt))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"confusion matrix: \\n\",confusion_matrix(y_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "be8ad6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model:  0.9974\n",
      "-------------------------------------------\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4305\n",
      "           1       1.00      1.00      1.00      4262\n",
      "\n",
      "    accuracy                           1.00      8567\n",
      "   macro avg       1.00      1.00      1.00      8567\n",
      "weighted avg       1.00      1.00      1.00      8567\n",
      "\n",
      "-------------------------------------------\n",
      "confusion matrix: \n",
      " [[4295   10]\n",
      " [  12 4250]]\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_array, labels, test_size=0.2, random_state=42)\n",
    "gb.fit(x_train,y_train)\n",
    "y_pred_gb = gb.predict(x_test)\n",
    "accuracy_gb =round(accuracy_score(y_test,y_pred_gb),4)\n",
    "print(\"Accuracy of Model: \",accuracy_gb)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Classification report: \\n\",classification_report(y_test,y_pred_gb))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"confusion matrix: \\n\",confusion_matrix(y_test,y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "0e126370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Concatenate corpus_t and corpus_f\n",
    "corpus = corpus_t + corpus_f\n",
    "\n",
    "# Tokenize the corpus\n",
    "tokenized_corpus = [text.split() for text in corpus]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(tokenized_corpus, min_count=1)\n",
    "\n",
    "# Get the word vectors\n",
    "word_vectors = model.wv\n",
    "\n",
    "# Example usage\n",
    "vector = word_vectors['word']  # Get vector for a specific word\n",
    "similar_words = word_vectors.most_similar('word')  # Get most similar words to a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0ecff2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9563441111240808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_average_vector(text, word_vectors):\n",
    "    vectors = [word_vectors[word] for word in text if word in word_vectors]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "\n",
    "# Convert corpus_t to feature vectors\n",
    "corpus_t_vectors = [get_average_vector(text.split(), word_vectors) for text in corpus_t]\n",
    "\n",
    "# Convert corpus_f to feature vectors\n",
    "corpus_f_vectors = [get_average_vector(text.split(), word_vectors) for text in corpus_f]\n",
    "\n",
    "# Combine the feature vectors and create the target labels\n",
    "X = np.concatenate([corpus_t_vectors, corpus_f_vectors], axis=0)\n",
    "y = np.concatenate([np.ones(len(corpus_t_vectors)), np.zeros(len(corpus_f_vectors))])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788d120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
