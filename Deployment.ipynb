{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bdc152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('rf.pkl')\n",
    "\n",
    "# Define custom stopwords\n",
    "custom_stopwords = [\n",
    "    'according', 'administration', 'also', 'america', 'american', 'americans', 'another', 'back', 'bill', 'black',\n",
    "    'called', 'campaign', 'clinton', 'could', 'country', 'day', 'department', 'donald', 'election', 'even', 'every',\n",
    "    'fact', 'first', 'former', 'fox', 'get', 'go', 'going', 'good', 'government', 'group', 'hillary', 'house',\n",
    "    'Image', 'it', 'know', 'last', 'law', 'like', 'made', 'make', 'may', 'media', 'much', 'national', 'never', 'new',\n",
    "    'news', 'man', 'many', 'obama', 'office', 'one', 'party', 'people', 'police', 'political', 'president',\n",
    "    'presidential', 'public', 'really', 'republican', 'republicans', 'right', 'said', 'say', 'says', 'see', 'show',\n",
    "    'since', 'state', 'states', 'still', 'support', 'take', 'think', 'time', 'told', 'trump', 'two', 'united', 'us',\n",
    "    'via', 'video', 'vote', 'white', 'women', 'world', 'would', 'year', 'years', 'want'\n",
    "]\n",
    "\n",
    "# Initialize NLTK components\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[\\x1d\\x1c\\x1b]', '', text)\n",
    "    text = re.sub(r'\\x19', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub('http\\S+\\s*', ' ', text)\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = word_tokenize(text.lower())\n",
    "    text = [word for word in text if word.lower() not in stop_words]\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "# Function to predict the class\n",
    "def predict_class(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    tfidf_text = vectorizer.transform([preprocessed_text])\n",
    "    prediction = model.predict(tfidf_text)[0]\n",
    "    return prediction\n",
    "\n",
    "# Load the TfidfVectorizer\n",
    "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Streamlit app\n",
    "def main():\n",
    "    st.title('News Classifier')\n",
    "    st.write('Enter a news text to classify it as real or fake:')\n",
    "    text_input = st.text_area('Input Text', height=200)\n",
    "    if st.button('Classify'):\n",
    "        if text_input:\n",
    "            prediction = predict_class(text_input)\n",
    "            if prediction == 1:\n",
    "                st.write('The news is classified as **real**.')\n",
    "            else:\n",
    "                st.write('The news is classified as **fake**.')\n",
    "        else:\n",
    "            st.write('Please enter a news text.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3afb48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
